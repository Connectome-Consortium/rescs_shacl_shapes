
@article{tkaczyk_new_2017,
	title = {New {Methods} for {Metadata} {Extraction} from {Scientific} {Literature}},
	url = {http://arxiv.org/abs/1710.10201},
	abstract = {Within the past few decades we have witnessed digital revolution, which moved scholarly communication to electronic media and also resulted in a substantial increase in its volume. Nowadays keeping track with the latest scientific achievements poses a major challenge for the researchers. Scientific information overload is a severe problem that slows down scholarly communication and knowledge propagation across the academia. Modern research infrastructures facilitate studying scientific literature by providing intelligent search tools, proposing similar and related documents, visualizing citation and author networks, assessing the quality and impact of the articles, and so on. In order to provide such high quality services the system requires the access not only to the text content of stored documents, but also to their machine-readable metadata. Since in practice good quality metadata is not always available, there is a strong demand for a reliable automatic method of extracting machine-readable metadata directly from source documents. This research addresses these problems by proposing an automatic, accurate and flexible algorithm for extracting wide range of metadata directly from scientific articles in born-digital form. Extracted information includes basic document metadata, structured full text and bibliography section. Designed as a universal solution, proposed algorithm is able to handle a vast variety of publication layouts with high precision and thus is well-suited for analyzing heterogeneous document collections. This was achieved by employing supervised and unsupervised machine-learning algorithms trained on large, diverse datasets. The evaluation we conducted showed good performance of proposed metadata extraction algorithm. The comparison with other similar solutions also proved our algorithm performs better than competition for most metadata types.},
	urldate = {2021-07-09},
	journal = {arXiv:1710.10201 [cs]},
	author = {Tkaczyk, Dominika},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.10201},
	keywords = {Computer Science - Digital Libraries, Computer Science - Information Retrieval, H.3.7, I.7.5},
}

@book{feng_natural_2018,
	address = {Cham},
	edition = {1st ed. 2018},
	series = {Lecture {Notes} in {Artificial} {Intelligence}},
	title = {Natural {Language} {Processing} and {Chinese} {Computing}: 6th {CCF} {International} {Conference}, {NLPCC} 2017, {Dalian}, {China}, {November} 8-12, 2017, {Proceedings}},
	isbn = {978-3-319-73618-1},
	shorttitle = {Natural {Language} {Processing} and {Chinese} {Computing}},
	abstract = {This book constitutes the refereed proceedings of the 6th CCF International Conference on Natural Language Processing, NLPCC 2017, held in Dalian, China, in November 2017. The 47 full papers and 39 short papers presented were carefully reviewed and selected from 252 submissions. The papers are organized around the following topics: IR/search/bot; knowledge graph/IE/QA; machine learning; machine translation; NLP applications; NLP fundamentals; social networks; and text mining},
	number = {10619},
	publisher = {Springer International Publishing : Imprint: Springer},
	editor = {Feng, Yansong and Hong, Yu and Huang, Xuanjing and Jiang, Jing and Zhao, Dongyan},
	year = {2018},
	doi = {10.1007/978-3-319-73618-1},
	keywords = {Application software, Artificial intelligence, Artificial Intelligence, Computer Appl. in Administrative Data Processing, Information storage and retrieval, Information Storage and Retrieval, Information Systems Applications (incl. Internet), Natural language processing (Computer science), Natural Language Processing (NLP)},
}

@article{tkaczyk_cermine_2015,
	title = {{CERMINE}: automatic extraction of structured metadata from scientific literature},
	volume = {18},
	issn = {1433-2833, 1433-2825},
	shorttitle = {{CERMINE}},
	url = {http://link.springer.com/10.1007/s10032-015-0249-8},
	doi = {10.1007/s10032-015-0249-8},
	language = {en},
	number = {4},
	urldate = {2021-07-09},
	journal = {International Journal on Document Analysis and Recognition (IJDAR)},
	author = {Tkaczyk, Dominika and Szostek, Paweł and Fedoryszak, Mateusz and Dendek, Piotr Jan and Bolikowski, Łukasz},
	month = dec,
	year = {2015},
	pages = {317--335},
}

@phdthesis{boyd_automatic_2015,
	title = {Automatic {Metadata} {Extraction} - {The} {High} {Energy} {Physics} {Use} {Case}},
	url = {https://cds.cern.ch/record/2039361},
	abstract = {Automatic metadata extraction (AME) of scientific papers has been described as one of the hardest problems in document engineering. Heterogeneous content, varying style, and unpredictable placement of article components render the problem inherently indeterministic. Conditional random fields (CRF), a machine learning technique, can be used to classify document metadata amidst this uncertainty, annotating document contents with semantic labels. High energy physics (HEP) papers, such as those written at CERN, have unique content and structural characteristics, with scientific collaborations of thousands of authors altering article layouts dramatically. The distinctive qualities of these papers necessitate the creation of specialised datasets and model features. In this work we build an unprecedented training set of HEP papers and propose and evaluate a set of innovative features for CRF models. We build upon state-of-the-art AME software, GROBID, a tool coordinating a hierarchy of CRF models in a full document cascade. Through our extensions and our own robust experimentation pipeline, we cross-validate 66 experiment variations to find new improvements in feature engineering. We succeed in enhancing the two most crucial CRF models within the cascade, reducing error by up to 25\% for key classifications.},
	language = {de},
	urldate = {2021-07-09},
	school = {Ecole Polytechnique, Lausanne},
	author = {Boyd, Joseph},
	month = jul,
	year = {2015},
	note = {Number: CERN-THESIS-2015-105
Publication Title: CERN Document Server},
}

@article{eckle-kohler_automatically_2013,
	title = {Automatically assigning research methods to journal articles in the domain of social sciences: {Automatically} {Assigning} {Research} {Methods} to {Journal} {Articles} in the {Domain} of {Social} {Sciences}},
	volume = {50},
	issn = {00447870},
	shorttitle = {Automatically assigning research methods to journal articles in the domain of social sciences},
	url = {http://doi.wiley.com/10.1002/meet.14505001049},
	doi = {10.1002/meet.14505001049},
	language = {en},
	number = {1},
	urldate = {2021-06-09},
	journal = {Proceedings of the American Society for Information Science and Technology},
	author = {Eckle-Kohler, Judith and Nghiem, Tri-Duc and Gurevych, Iryna},
	year = {2013},
	pages = {1--8},
}

@article{lemoisson_collective_2021,
	title = {Collective and {Informal} {Learning} in the {ViewpointS} {Interactive} {Medium}},
	volume = {12},
	issn = {2078-2489},
	url = {https://www.mdpi.com/2078-2489/12/5/183},
	doi = {10.3390/info12050183},
	abstract = {Collective learning has been advocated to be at the source for innovation, particularly as serendipity seems historically to have been the driving force not only behind innovation, but also behind scientific discovery and artistic creation. Informal learning is well known to represent the most significant learning effects in humans, far better than its complement: formal learning with predefined objectives. We have designed an approach—ViewpointS—based on a digital medium—the ViewpointS Web Application—that enables and enhances the processes for sharing knowledge within a group and is equipped with metrics aimed at assessing collective and informal learning. In this article, we introduce by giving a brief state of the art about collective and informal learning, then outline our approach and medium, and finally, present and exploit a real-life experiment aimed at evaluating the ViewpointS approach and metrics.},
	language = {en},
	number = {5},
	urldate = {2021-05-19},
	journal = {Information},
	author = {Lemoisson, Philippe and Cerri, Stefano A. and Douzal, Vincent and Dugénie, Pascal and Tonneau, Jean-Philippe},
	month = apr,
	year = {2021},
	pages = {183},
}

@misc{noauthor_nachnutzung_nodate,
	title = {Nachnutzung und {Anreicherung} von {Metadaten} aus institutionellen {Open} {Access} {Repositorien} - {PDF} {Kostenfreier} {Download}},
	url = {https://docplayer.org/207151371-Nachnutzung-und-anreicherung-von-metadaten-aus-institutionellen-open-access-repositorien.html},
	urldate = {2021-05-19},
}

@book{balog_entity-oriented_2018,
	address = {Cham},
	series = {The {Information} {Retrieval} {Series}},
	title = {Entity-{Oriented} {Search}},
	volume = {39},
	isbn = {978-3-319-93933-9 978-3-319-93935-3},
	url = {http://link.springer.com/10.1007/978-3-319-93935-3},
	language = {en},
	urldate = {2021-04-09},
	publisher = {Springer International Publishing},
	author = {Balog, Krisztian},
	year = {2018},
	doi = {10.1007/978-3-319-93935-3},
}

@inproceedings{zhu_collective_2020,
	address = {Taipei Taiwan},
	title = {Collective {Multi}-type {Entity} {Alignment} {Between} {Knowledge} {Graphs}},
	isbn = {978-1-4503-7023-3},
	url = {https://dl.acm.org/doi/10.1145/3366423.3380289},
	doi = {10.1145/3366423.3380289},
	language = {en},
	urldate = {2021-04-09},
	booktitle = {Proceedings of {The} {Web} {Conference} 2020},
	publisher = {ACM},
	author = {Zhu, Qi and Wei, Hao and Sisman, Bunyamin and Zheng, Da and Faloutsos, Christos and Dong, Xin Luna and Han, Jiawei},
	month = apr,
	year = {2020},
	pages = {2241--2252},
}

@inproceedings{balog_personal_2019,
	address = {Santa Clara CA USA},
	title = {Personal {Knowledge} {Graphs}: {A} {Research} {Agenda}},
	isbn = {978-1-4503-6881-0},
	shorttitle = {Personal {Knowledge} {Graphs}},
	url = {https://dl.acm.org/doi/10.1145/3341981.3344241},
	doi = {10.1145/3341981.3344241},
	language = {en},
	urldate = {2021-04-09},
	booktitle = {Proceedings of the 2019 {ACM} {SIGIR} {International} {Conference} on {Theory} of {Information} {Retrieval}},
	publisher = {ACM},
	author = {Balog, Krisztian and Kenter, Tom},
	month = sep,
	year = {2019},
	pages = {217--220},
}

@incollection{sakr_knowledge_2018,
	address = {Cham},
	title = {Knowledge {Graphs} in the {Libraries} and {Digital} {Humanities} {Domain}},
	isbn = {978-3-319-63962-8},
	url = {http://link.springer.com/10.1007/978-3-319-63962-8_291-1},
	language = {en},
	urldate = {2021-04-09},
	booktitle = {Encyclopedia of {Big} {Data} {Technologies}},
	publisher = {Springer International Publishing},
	author = {Haslhofer, Bernhard and Isaac, Antoine and Simon, Rainer},
	editor = {Sakr, Sherif and Zomaya, Albert},
	year = {2018},
	doi = {10.1007/978-3-319-63962-8_291-1},
	pages = {1--8},
}

@misc{union_eosc_2021,
	type = {Website},
	title = {{EOSC} interoperability framework : report from the {EOSC} {Executive} {Board} {Working} {Groups} {FAIR} and {Architecture}.},
	shorttitle = {{EOSC} interoperability framework},
	url = {http://op.europa.eu/en/publication-detail/-/publication/d787ea54-6a87-11eb-aeb5-01aa75ed71a1/language-en/format-PDF},
	abstract = {This document has been developed by the Interoperability Task Force of the EOSC Executive Board FAIR Working Group, with participation from the Architecture WG. Achieving interoperability within EOSC is essential in order for the federation of services that will compose EOSC to provide added value for service users. In the context of the FAIR principles, interoperability is discussed in relation to the fact that “research data usually need to be integrated with other data; in addition, the data need to interoperate with applications or workflows for analysis, storage, and processing”. Our view on interoperability does not only consider data but also the many other research artefacts that may be used in the context of research activity, such as software code, scientific workflows, laboratory protocols, open hardware designs, etc. It also considers the need to make services and e-infrastructures as interoperable as possible. This document identifies the general principles that should drive the creation of the EOSC Interoperability Framework (EOSC IF), and organises them into the four layers that are commonly considered in other interoperability frameworks (e.g., the European Interoperability Framework - EIF): technical, semantic, organisational and legal interoperability. For each of these layers, a catalogue of problems and needs, as well as challenges and high-level recommendations have been proposed, which should be considered in the further development and implementation of the EOSC IF components. Such requirements and recommendations have been developed after an extensive review of related literature as well as by running interviews with stakeholders from ERICs (European Research Infrastructure Consortia), ESFRI (European Strategy Forum on Research Infrastructures) projects, service providers and research communities. Some examples of such requirements are: “every semantic artefact that is being maintained in EOSC must have sufficient associated documentation, with clear examples of usage and conceptual diagrams”, or “Coarse-grained and fine-grained dataset (and other research object) search tools need to be made available”, etc. The document finally contains a proposal for the management of FAIR Digital Objects in the context of EOSC and a reference architecture for the EOSC Interoperability Framework that is inspired by and extends the European Interoperability Reference Architecture (EIRA), identifying the main building blocks required.},
	language = {en},
	urldate = {2021-03-17},
	author = {Union, Publications Office of the European},
	month = feb,
	year = {2021},
	note = {ISBN: 9789276289494
Publisher: Publications Office of the European Union},
}

@misc{noauthor_ontologien_nodate,
	title = {Ontologien — {Enzyklopaedie} der {Wirtschaftsinformatik}},
	url = {https://www.enzyklopaedie-der-wirtschaftsinformatik.de/lexikon/daten-wissen/Wissensmanagement/Wissensmodellierung/Wissensreprasentation/Semantisches-Netz/Ontologien},
	urldate = {2021-03-16},
}

@article{wurtz_archival_2020,
	title = {Archival {Linked} ({Open}) {Data}: {Empfehlungen} für bestehende {Metadaten} und {Massnahmen} für die {Zukunft} am {Fallbeispiel} des {Schweizerischen} {Sozialarchivs}},
	volume = {6},
	issn = {2297-9069},
	shorttitle = {Archival {Linked} ({Open}) {Data}},
	url = {https://bop.unibe.ch/iw/article/view/7083},
	doi = {10.18755/iw.2020.17},
	abstract = {Eine Kernaufgabe der Archive ist die Erschliessung des Archivguts. Bisher wurden Archivbestände meist als hierarchische und isolierte Einheiten verzeichnet. Die zunehmende Digitalisierung, neue Fachbereiche wie die Digital Humanities oder Entwicklungen wie das Semantic Web bzw. Linked Open Data haben jedoch neue Ideen in die Archivwelt getragen. Einer der deutlichsten Vorboten dieser neuen Welt ist Records in Context (RiC). Der neue Verzeichnungsstandard des wichtigen International Council on Archives (ICA) ist konzeptionell auf Linked Open Data und das Semantic Web ausgerichtet. Doch was bedeutet es für die Archive, wenn aus den bisher isolierten Beständen verlinkte und maschinenlesbare Netzwerke entstehen sollen? Wie sollen archivalische Metadaten und Datenmodelle in Linked Open Data aussehen und an welche Qualitätsansprüche sollen diese neu berücksichtigen?Um diese Fragen zu beantworten hat die Arbeit das Konzept und die Technologien die Linked Open Data zugrunde liegen vorgestellt. Danach wurden Qualitätsmerkmale für Linked Open Data zusammengetragen und der momentane Stand von Linked Open Data im Archivbereich beleuchtet. Dabei wurde unter anderem bereits existierende Ansätze und Anwendungen aus dem Archivbereich vorgestellt und mit den Qualitätsmerkmalen verglichen. Die Überprüfung der Praxistauglichkeit der Qualitätsmerkmale erfolgte am Fallbeispiel der Metadaten des Schweizerischen Sozialarchivs.Auf Basis der erarbeitenden Resultate spricht die Arbeit eine Reihe von Empfehlungen aus. Diese richten sich an Archive, die sich mit dem Thema Linked Open Data beschäftigen oder eine Anwendung in diesem Bereich planen.},
	number = {1},
	urldate = {2021-03-16},
	journal = {Informationswissenschaft: Theorie, Methode und Praxis},
	author = {Würtz, Fabian},
	month = jul,
	year = {2020},
	pages = {312--423},
}

@misc{farber_michael_microsoft_2020,
	title = {The {Microsoft} {Academic} {Graph} in {RDF}: {A} {Linked} {Data} {Source} with 8 {Billion} {Triples} of {Scholarly} {Data}},
	copyright = {Open Data Commons Attribution License v1.0, Open Access},
	shorttitle = {The {Microsoft} {Academic} {Graph} in {RDF}},
	url = {https://zenodo.org/record/3936556},
	abstract = {We provide an updated version of the {\textless}strong{\textgreater}Microsoft Academic Knowledge Graph (MAKG){\textless}/strong{\textgreater}. The MAKG is a {\textless}strong{\textgreater}large RDF knowledge graph {\textless}/strong{\textgreater}with {\textless}strong{\textgreater}over eight billion triples{\textless}/strong{\textgreater} containing information about scientific {\textless}strong{\textgreater}publications{\textless}/strong{\textgreater} and related entities, such as {\textless}strong{\textgreater}authors{\textless}/strong{\textgreater}, {\textless}strong{\textgreater}institutions{\textless}/strong{\textgreater}, {\textless}strong{\textgreater}journals{\textless}/strong{\textgreater}, and {\textless}strong{\textgreater}fields of study{\textless}/strong{\textgreater}. The provided data is based on the MAG data as of {\textless}strong{\textgreater}2020-05-29{\textless}/strong{\textgreater}. Besides the MAKG core data, also the owl:sameAs-links to Wikidata and OpenCitations were updated. More information can be found at {\textless}strong{\textgreater}http://ma-graph.org/{\textless}/strong{\textgreater} and in the ISWC'19 paper {\textless}strong{\textgreater}The Microsoft Academic Knowledge Graph: A Linked Data Source with 8 Billion Triples of Scholarly Data{\textless}/strong{\textgreater} (author copy available here). If you use the data set, please cite it as follows (see also in DBLP): Michael Färber: "The Microsoft Academic Knowledge Graph: A Linked Data Source with 8 Billion Triples of Scholarly Data". Proceedings of the 18th International Semantic Web Conference (ISWC'19). Auckland, New Zealand, 2019, pp. 113-129. {\textless}pre{\textgreater}{\textless}code{\textgreater}@inproceedings\{DBLP:conf/semweb/Farber19, author = "\{Michael F\{{\textbackslash}"\{a\}\}rber\}", title = "\{The Microsoft Academic Knowledge Graph: \{A\} Linked Data Source with 8 Billion Triples of Scholarly Data\}", booktitle = "\{Proceedings of the 18th International Semantic Web Conference\}", series = "\{ISWC'19\}", location = "\{Auckland, New Zealand\}", pages = \{113--129\}, year = \{2019\}, url = \{https://doi.org/10.1007/978-3-030-30796-7{\textbackslash}\_8\}, doi = \{10.1007/978-3-030-30796-7{\textbackslash}\_8\} \} {\textless}/code{\textgreater}{\textless}/pre{\textgreater}},
	urldate = {2021-03-10},
	publisher = {Zenodo},
	author = {Färber, Michael},
	month = jul,
	year = {2020},
	doi = {10.5281/ZENODO.3936556},
	note = {Version Number: 2020-05-29
type: dataset},
	keywords = {Academia, Digitial Libraries, Knowledge Graph, Linked Open Data, RDF, Scholarly Data},
}

@incollection{ghidini_microsoft_2019,
	address = {Cham},
	title = {The {Microsoft} {Academic} {Knowledge} {Graph}: {A} {Linked} {Data} {Source} with 8 {Billion} {Triples} of {Scholarly} {Data}},
	volume = {11779},
	isbn = {978-3-030-30795-0 978-3-030-30796-7},
	shorttitle = {The {Microsoft} {Academic} {Knowledge} {Graph}},
	url = {http://link.springer.com/10.1007/978-3-030-30796-7_8},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {The {Semantic} {Web} – {ISWC} 2019},
	publisher = {Springer International Publishing},
	author = {Färber, Michael},
	editor = {Ghidini, Chiara and Hartig, Olaf and Maleshkova, Maria and Svátek, Vojtěch and Cruz, Isabel and Hogan, Aidan and Song, Jie and Lefrançois, Maxime and Gandon, Fabien},
	year = {2019},
	doi = {10.1007/978-3-030-30796-7_8},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {113--129},
}

@inproceedings{casas-bayona_integrating_2014,
	address = {Vienna, Austria},
	title = {Integrating {Semi}-structured {Information} using {Semantic} {Technologies} - {An} {Evaluation} of {Tools} and a {Case} {Study} on {University} {Rankings} {Data}:},
	isbn = {978-989-758-035-2},
	shorttitle = {Integrating {Semi}-structured {Information} using {Semantic} {Technologies} - {An} {Evaluation} of {Tools} and a {Case} {Study} on {University} {Rankings} {Data}},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005004203570364},
	doi = {10.5220/0005004203570364},
	urldate = {2021-03-05},
	booktitle = {Proceedings of 3rd {International} {Conference} on {Data} {Management} {Technologies} and {Applications}},
	publisher = {SCITEPRESS - Science and and Technology Publications},
	author = {Casas-Bayona, Alejandra and Ceballos, Hector G.},
	year = {2014},
	pages = {357--364},
}

@misc{noauthor_building_nodate,
	title = {Building an {Ontology} to {Specify} the {TRIPLE} {Data} {Model} {Proposal} for a {Beta} {Version}},
	url = {https://halshs.archives-ouvertes.fr/halshs-03085854/document},
	abstract = {This article describes the conceptual and pragmatic choices that led to the construction of an ontology whose objective is to prepare the complete specification of the
TRIPLE data model.},
	author = {, , Melanie Bunel and Jean-Luc Minel, and Stéphane Pouyllau},
}

@misc{noy_ontology_nodate,
	title = {Ontology {Development} 101: {A} {Guide} to {Creating} {Your} {First} {Ontology}},
	url = {http://www.ksl.stanford.edu/people/dlm/papers/ontology-tutorial-noy-mcguinness-abstract.html},
	abstract = {ontologies, chimaera, protege, ontolingua, markup, web, www},
	urldate = {2021-02-26},
	author = {Noy, Natalya and McGuinness, Deborah},
}

@article{peroni_simplified_nodate,
	title = {A {Simplified} {Agile} {Methodology} for {Ontology} {Development}},
	url = {https://www.w3.org/community/owled/files/2016/11/OWLED-ORE-2016_paper_6.pdf},
	author = {Peroni, Silvio},
}

@misc{noy_ontology_nodate-1,
	title = {Ontology {Development} 101: {A} {Guide} to {Creating} {Your} {First} {Ontology}},
	url = {http://www.ksl.stanford.edu/people/dlm/papers/ontology-tutorial-noy-mcguinness.pdf},
	author = {Noy, Natalya F. and Deborah L. McGuinness},
}

@article{altenhoner_reinhard_fokusthemen_2019,
	title = {Fokusthemen und {Aufgabenbereiche} für eine {Forschungsdateninfrastruktur} zu materiellen und immateriellen {Kulturgütern}. {Living} {Document} der {NFDI}-{Initiative} {NFDI4Culture}.},
	copyright = {Creative Commons Attribution Share Alike 4.0 International, Open Access},
	url = {https://zenodo.org/record/2763576},
	doi = {10.5281/ZENODO.2763576},
	abstract = {In der Konsortiumsinitiative „NFDI4Culture“ haben sich Partner*innen aus Forschung, Gedächtnisinstitutionen und Infrastruktureinrichtungen zusammengefunden, die sich dem Aufbau einer dezentralen, fach- und forschungsnahen Infrastruktur für Forschungsdaten aus dem Bereich der materiellen und immateriellen Kulturgüter widmen. Die wissenschaftliche Notwendigkeit und zugleich das kulturpolitische Potential von NFDI4Culture ergibt sich aus den Besonderheiten der beforschten, primär nicht-textuellen Güter, deren materiale und mediale Dimensionen einen Eigenwert besitzen, der nicht vollständig in einer digitalen Repräsentation aufgeht. Als Abformung eines Kulturguts kann das Digitalisat zudem seinerseits immaterielles Kulturgut werden, z. B. bei Verlust oder Zerstörung des materiellen Objekts, durch die Geschichtlichkeit medialer Objekte u.a.m. Der bisherige Austausch zwischen den einzelnen Partner*innen von NFDI4Culture dient dabei der Selbstverständigung zu Aufgaben und Zielen eines möglichen NFDI-Konsortiums und profitiert von den spezifischen Perspektiven und Kompetenzen aller Beteiligten. So werden Wissenstransfer und eine gemeinsame Sprechfähigkeit gewährleistet und befördert. Die vorliegenden Texte werden in diesem frühen Stadium des allgemeinen NFDI-Prozesses als Positionsbestimmung vorgelegt und dienen als Bezugspunkt für Diskussionen zu den für eine NFDI4Culture charakteristischen Herausforderungen in einem größeren Kontext: sowohl in und mit den Fachcommunities als auch zwischen den verschiedenen Konsortiumsinitiativen. Aufgabenfelder und Ziele einer NFDI4Culture können, werden und sollen sich entsprechend der in der Diskussion formulierten Bedarfe anpassen und weiterentwickeln. Das vorliegende „Living Document“ dient dabei als Referenzpunkt, in dem die verschiedenen, dynamisch fortlaufenden Diskussionen an einer Stelle immer wieder transparent gebündelt und dokumentiert werden.},
	language = {de},
	urldate = {2021-02-24},
	author = {Altenhöner, Reinhard and Bicher, Katrin and Bracht, Christian and Brand, Ortrun and Blümel, Ina and Bulle, Klaus and Effinger, Maria and Hammes, Andrea and Hartmann, Thomas and Kailus, Angela and Kett, Jürgen and Pittroff, Sarah and Röwenstrunk, Daniel and Schelbert, Georg and Schmidt, Dörte and Schrade, Torsten and Simon, Holger and Taentzer, Gabriele and Veit, Joachim and Voß, Franziska and Walzel, Annika-Valeska and Wiermann, Barbara},
	month = may,
	year = {2019},
	note = {Publisher: Zenodo
Version Number: 1.0},
	keywords = {NFDI, NFDI4Culture, research data, research software, data literacy, code literacy, rights management, data ethics, authority data, data quality},
}

@book{putnings_praxishandbuch_2021,
	title = {Praxishandbuch {Forschungsdatenmanagement}},
	isbn = {978-3-11-065780-7 978-3-11-065365-6},
	url = {https://www.degruyter.com/view/title/554542},
	urldate = {2021-02-22},
	publisher = {De Gruyter Saur},
	editor = {Putnings, Markus and Neuroth, Heike and Neumann, Janna},
	month = jan,
	year = {2021},
	doi = {10.1515/9783110657807},
}

@misc{kurt_baumann_etal_ord_hackathon_group11_presentation_slides_identification_of_personas_2021,
	title = {{ORD}\_Hackathon\_Group11\_Presentation\_Slides\_Identification\_of\_Personas},
	url = {https://docs.google.com/presentation/d/1ypvuDV9OkFzl1KNGCI7l8Xgpll913wOkXwtSZN1Y-8E/edit?usp=sharing&usp=embed_facebook},
	abstract = {Identification of personas (who is who) Team \#11 - Research Data Connectome: Anna Keller, Laura Rettig, Alexis Rapin, Nobutake Kamiya, Kurt Baumann},
	language = {en-GB},
	urldate = {2021-02-12},
	journal = {Google Docs},
	author = {Kurt Baumann (et.al)},
	month = dec,
	year = {2021},
}

@incollection{hadorn_enhancing_2008,
	address = {Dordrecht},
	title = {Enhancing {Transdisciplinary} {Research}: {A} {Synthesis} in {Fifteen} {Propositions}},
	isbn = {978-1-4020-6698-6 978-1-4020-6699-3},
	shorttitle = {Enhancing {Transdisciplinary} {Research}},
	url = {http://link.springer.com/10.1007/978-1-4020-6699-3_29},
	language = {en},
	urldate = {2021-02-15},
	booktitle = {Handbook of {Transdisciplinary} {Research}},
	publisher = {Springer Netherlands},
	author = {Wiesmann, Urs and Biber-Klemm, Susette and Grossenbacher-Mansuy, Walter and Hadorn, Gertrude Hirsch and Hoffmann-Riem, Holger and Joye, Dominique and Pohl, Christian and Zemp, Elisabeth},
	editor = {Hadorn, Gertrude Hirsch and Hoffmann-Riem, Holger and Biber-Klemm, Susette and Grossenbacher-Mansuy, Walter and Joye, Dominique and Pohl, Christian and Wiesmann, Urs and Zemp, Elisabeth},
	year = {2008},
	doi = {10.1007/978-1-4020-6699-3_29},
	pages = {433--441},
}

@article{pedersen_integrating_2016,
	title = {Integrating social sciences and humanities in interdisciplinary research},
	volume = {2},
	issn = {2055-1045},
	url = {https://doi.org/10.1057/palcomms.2016.36},
	doi = {10.1057/palcomms.2016.36},
	abstract = {Recent attempts to integrate the social sciences and humanities (SSH) in funding for interdisciplinary research have been challenged by a number of barriers. In funding programmes, such as the EU Horizon 2020, the SSH are absent in most calls for contributions. This article revisits the main policy drivers for embedding SSH research in interdisciplinary research. By analysing recent policy initiatives, the article shows how policymakers across the world continue to be ambivalent regarding the role of the SSH. While many stakeholders acknowledge the need to integrate SSH research in solving key societal challenges, such as climate change, migration or national security, funding for SSH is limited and tends to focus on strategic interventions and instrumental solutions. By accounting for the diversity of interdisciplinary collaborations the article recommends a more context-sensitive approach to research funding, which acknowledges the heterogeneity and volatility of research across different knowledge environments. This article is published as part of a thematic collection on the concept of interdisciplinarity.},
	number = {1},
	journal = {Palgrave Communications},
	author = {Pedersen, David Budtz},
	month = jul,
	year = {2016},
	pages = {16036},
}

@incollection{fensel_how_2020,
	address = {Cham},
	title = {How to {Use} a {Knowledge} {Graph}},
	isbn = {978-3-030-37439-6},
	url = {https://doi.org/10.1007/978-3-030-37439-6_3},
	abstract = {Intelligent Personal AssistantsPersonal assistantare changing the way we access the information on the web as search enginesSearch enginechanged it years ago. Undoubtfully, an important factor that enables this way of consuming the web is the schema.orgSchema.organnotationsAnnotationson websites. Those annotationsAnnotationsare extracted and then consumed by search engines and Intelligent Personal AssistantsPersonal assistantto support tasks like question-answering. In this section we explain how Knowledge Graphs built based on content, data, and service annotationsAnnotationscan improve search engine results and conversational systems. We first give a brief overview of the history of the Internet, AI, and web and the role semantic technologies is playing in bringing those three to the point we are today. Then we show the need for an abstraction layer over Knowledge Graphs where we can create different knowledge views in order to achieve scalable curation, reasoning, and access control. Finally, we show how Knowledge Graphs can power conversational agents in different points in the dialog systemDialog systempipeline and the promising future of service annotationsAnnotationshelping to build flexible systems decoupled from the web services with which they communicate.},
	booktitle = {Knowledge {Graphs}: {Methodology}, {Tools} and {Selected} {Use} {Cases}},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	editor = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6_3},
	pages = {69--93},
}

@incollection{fensel_how_2020-1,
	address = {Cham},
	title = {How to {Use} a {Knowledge} {Graph}},
	isbn = {978-3-030-37439-6},
	url = {https://doi.org/10.1007/978-3-030-37439-6_3},
	abstract = {Intelligent Personal AssistantsPersonal assistantare changing the way we access the information on the web as search enginesSearch enginechanged it years ago. Undoubtfully, an important factor that enables this way of consuming the web is the schema.orgSchema.organnotationsAnnotationson websites. Those annotationsAnnotationsare extracted and then consumed by search engines and Intelligent Personal AssistantsPersonal assistantto support tasks like question-answering. In this section we explain how Knowledge Graphs built based on content, data, and service annotationsAnnotationscan improve search engine results and conversational systems. We first give a brief overview of the history of the Internet, AI, and web and the role semantic technologies is playing in bringing those three to the point we are today. Then we show the need for an abstraction layer over Knowledge Graphs where we can create different knowledge views in order to achieve scalable curation, reasoning, and access control. Finally, we show how Knowledge Graphs can power conversational agents in different points in the dialog systemDialog systempipeline and the promising future of service annotationsAnnotationshelping to build flexible systems decoupled from the web services with which they communicate.},
	booktitle = {Knowledge {Graphs}: {Methodology}, {Tools} and {Selected} {Use} {Cases}},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	editor = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6_3},
	pages = {69--93},
}

@incollection{fensel_how_2020-2,
	address = {Cham},
	title = {How to {Build} a {Knowledge} {Graph}},
	isbn = {978-3-030-37438-9 978-3-030-37439-6},
	url = {http://link.springer.com/10.1007/978-3-030-37439-6_2},
	language = {en},
	urldate = {2021-02-15},
	booktitle = {Knowledge {Graphs}},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	collaborator = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6_2},
	pages = {11--68},
}

@inproceedings{auer_creating_2011,
	address = {Sogndal, Norway},
	title = {Creating knowledge out of interlinked data: making the web a data washing machine},
	isbn = {978-1-4503-0148-0},
	shorttitle = {Creating knowledge out of interlinked data},
	url = {http://portal.acm.org/citation.cfm?doid=1988688.1988693},
	doi = {10.1145/1988688.1988693},
	language = {en},
	urldate = {2021-02-15},
	booktitle = {Proceedings of the {International} {Conference} on {Web} {Intelligence}, {Mining} and {Semantics} - {WIMS} '11},
	publisher = {ACM Press},
	author = {Auer, Sören},
	year = {2011},
	pages = {1},
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Groups} {\textgreater} {Connectome}-{Project}},
	url = {https://www.zotero.org/groups/2768669/connectome-project},
	urldate = {2021-02-12},
}

@misc{kurt_baumann_etal_ord_hackathon_group11_identifiation_of_personas_2021,
	title = {{ORD}\_Hackathon\_Group11\_Identifiation\_of\_Personas},
	shorttitle = {Identification of {Persona}},
	url = {https://docs.google.com/document/d/1-a5ecGQA7tkAnFlgkmUaLm5gFb8KN8ZSem0lyKQvtow/edit?usp=sharing&usp=embed_facebook},
	abstract = {Identification of Personas (who is who) Task \#11 Participants Anna Keller, Laura Rettig, Alexis Rapin, Nobutake Kamiya, Kurt Baumann Presentation:  https://docs.google.com/presentation/d/1ypvuDV9OkFzl1KNGCI7l8Xgpll913wOkXwtSZN1Y-8E/edit?usp=sharing Introduction and Workflow  Our work was inspired...},
	language = {en-GB},
	urldate = {2021-02-12},
	journal = {Google Docs},
	author = {{Kurt Baumann (et.al)}},
	month = dec,
	year = {2021},
}

@article{kalampokis_modeling_2019,
	title = {On modeling linked open statistical data},
	volume = {55},
	issn = {15708268},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1570826818300544},
	doi = {10.1016/j.websem.2018.11.002},
	language = {en},
	urldate = {2021-02-12},
	journal = {Journal of Web Semantics},
	author = {Kalampokis, Evangelos and Zeginis, Dimitris and Tarabanis, Konstantinos},
	month = mar,
	year = {2019},
	pages = {56--68},
}

@incollection{patel-schneider_linking_2010,
	address = {Berlin, Heidelberg},
	title = {Linking and {Building} {Ontologies} of {Linked} {Data}},
	volume = {6496},
	isbn = {978-3-642-17745-3 978-3-642-17746-0},
	url = {http://link.springer.com/10.1007/978-3-642-17746-0_38},
	urldate = {2021-02-11},
	booktitle = {The {Semantic} {Web} – {ISWC} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Parundekar, Rahul and Knoblock, Craig A. and Ambite, José Luis},
	editor = {Patel-Schneider, Peter F. and Pan, Yue and Hitzler, Pascal and Mika, Peter and Zhang, Lei and Pan, Jeff Z. and Horrocks, Ian and Glimm, Birte},
	year = {2010},
	doi = {10.1007/978-3-642-17746-0_38},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {598--614},
}

@inproceedings{parundekar_linking_2010,
	address = {Berlin, Heidelberg},
	title = {Linking and {Building} {Ontologies} of {Linked} {Data}},
	isbn = {978-3-642-17746-0},
	abstract = {The Web of Linked Data is characterized by linking structured data from different sources using equivalence statements, such as owl:sameAs, as well as other types of linked properties. The ontologies behind these sources, however, remain unlinked. This paper describes an extensional approach to generate alignments between these ontologies. Specifically our algorithm produces equivalence and subsumption relationships between classes from ontologies of different Linked Data sources by exploring the space of hypotheses supported by the existing equivalence statements. We are also able to generate a complementary hierarchy of derived classes within an existing ontology or generate new classes for a second source where the ontology is not as refined as the first. We demonstrate empirically our approach using Linked Data sources from the geospatial, genetics, and zoology domains. Our algorithm discovered about 800 equivalences and 29,000 subset relationships in the alignment of five source pairs from these domains. Thus, we are able to model one Linked Data source in terms of another by aligning their ontologies and understand the semantic relationships between the two sources.},
	booktitle = {The {Semantic} {Web} – {ISWC} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Parundekar, Rahul and Knoblock, Craig A. and Ambite, José Luis},
	editor = {Patel-Schneider, Peter F. and Pan, Yue and Hitzler, Pascal and Mika, Peter and Zhang, Lei and Pan, Jeff Z. and Horrocks, Ian and Glimm, Birte},
	year = {2010},
	pages = {598--614},
}

@article{albert_merono-penuela_semantic_nodate,
	title = {Semantic {Web} for the {Humanities}},
	url = {https://www.albertmeronyo.org/wp-content/uploads/2013/05/eswc2013-dc-final.pdf},
	urldate = {2021-02-11},
	author = {Albert Meroño-Peñuela},
}

@book{auer_linked_2014,
	address = {Cham},
	series = {Lecture notes in computer science {Information} systems and applications, incl. {Internet}/web, and {HCI}},
	title = {Linked open data - creating knowledge out of interlinked data: results of the {LOD2} project},
	isbn = {978-3-319-09846-3 978-3-319-09845-6},
	shorttitle = {Linked open data - creating knowledge out of interlinked data},
	language = {eng},
	number = {8661},
	publisher = {Springer},
	editor = {Auer, Sören and Bryl, Volha and Tramp, Sebastian},
	year = {2014},
	note = {OCLC: 896112545},
}

@book{fensel_knowledge_2020,
	address = {Cham},
	title = {Knowledge {Graphs}: {Methodology}, {Tools} and {Selected} {Use} {Cases}},
	isbn = {978-3-030-37438-9 978-3-030-37439-6},
	shorttitle = {Knowledge {Graphs}},
	url = {http://link.springer.com/10.1007/978-3-030-37439-6},
	language = {en},
	urldate = {2021-02-11},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6},
}

@incollection{roland_s_kamzelak_editionen_2016,
	address = {München},
	title = {Editionen im semantic web. {Chancen} und {Grenzen} von {Normdaten}, {FRBR} und {RDF}},
	booktitle = {Ei, dem alten {Herrn} zoll' ich {Achtung} gern'". {Festschrift} für {Joachim} {Veit} zum 60. {Geburtstag}},
	publisher = {Allitera},
	author = {Roland S. Kamzelak},
	year = {2016},
}

@book{richts_ei_2018,
	edition = {2016},
	title = {„{Ei}, dem alten {Herrn} zoll’ ich {Achtung} gern“},
	isbn = {978-3-86906-842-8},
	url = {https://nbn-resolving.org/urn:nbn:de:bsz:14-qucosa2-209533},
	urldate = {2021-02-11},
	publisher = {Allitera Verlag, München},
	author = {Richts, Kristina and Stadler, Peter},
	month = mar,
	year = {2018},
	doi = {10.25366/2018.2},
}

@misc{sebastian_sigloch_linked_nodate,
	title = {Linked data for the future - {SWITCH}},
	url = {https://www.switch.ch/stories/research-data-connetcome/},
	urldate = {2021-02-11},
	author = {Sebastian Sigloch},
}

@misc{cornelia_puhze_source_nodate,
	title = {From the source into the {Connectome} - {SWITCH}},
	url = {https://www.switch.ch/stories/source-to-connectome/},
	urldate = {2021-02-11},
	author = {Cornelia Puhze and Laura Rettig},
}

@misc{sebastian_sigloch_discover_nodate,
	title = {Discover and use {Linked} {Open} {Data} - {SWITCH}},
	url = {https://www.switch.ch/stories/Discover-linked-open-data/},
	urldate = {2021-02-11},
	author = {Sebastian Sigloch},
}

@misc{andrea_bertino_connectome_nodate,
	title = {The {Connectome} {Knowledge} {Graph} - {SWITCH}},
	url = {https://www.switch.ch/stories/Connectome-knowledge-graph/},
	urldate = {2021-02-11},
	author = {Andrea Bertino},
}

@techreport{philippe_cudre-mauroux_switch_nodate,
	title = {{SWITCH} {Innovation} {Lab} “{Research} data connectome technologies”},
	url = {https://www.switch.ch/export/sites/default/about/innovation/.galleries/files/SWITCHInnovationLab_eXascale-InfoLab_Results.pdf},
	urldate = {2021-02-11},
	author = {Philippe Cudré-Mauroux},
}

@techreport{esther_koller-meier_switch_nodate,
	title = {{SWITCH} {Innovation} {Lab} “{Comprehensible} {Data} {Quality}“},
	url = {https://www.switch.ch/export/sites/default/about/innovation/.galleries/files/SWITCHInnovationLab_SATW_Results.pdf},
	urldate = {2021-02-11},
	author = {{Esther Koller-Meier} and {Manuel Kugler}},
}

@article{noauthor_notitle_nodate,
}

@inproceedings{simsek_domain-specific_2020,
	address = {Cham},
	title = {Domain-{Specific} {Customization} of {Schema}.org {Based} on {SHACL}},
	isbn = {978-3-030-62466-8},
	url = {https://drive.switch.ch/index.php/f/4052717079},
	doi = {https://doi.org/10.1007/978-3-030-62466-8_36},
	abstract = {Schema.org is a widely adopted vocabulary for semantic annotation of web resources. However, its generic nature makes it complicated for publishers to pick the right types and properties for a specific domain. In this paper, we propose an approach, a domain specification process that generates domain-specific patterns by applying operators implemented in SHACL syntax to the schema.org vocabulary. These patterns can support annotation generation and verification processes for specific domains. We provide tooling for the generation of such patterns and evaluate the usability of both domain-specific patterns and the tools with use cases in the tourism domain.},
	booktitle = {The {Semantic} {Web} – {ISWC} 2020},
	publisher = {Springer International Publishing},
	author = {Şimşek, Umutcan and Angele, Kevin and Kärle, Elias and Panasiuk, Oleksandra and Fensel, Dieter},
	editor = {Pan, Jeff Z. and Tamma, Valentina and d’Amato, Claudia and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
	year = {2020},
	pages = {585--600},
}

@article{simsek_formal_2019,
	title = {A formal approach for customization of schema.org based on {SHACL}},
	url = {http://arxiv.org/abs/1906.06492},
	abstract = {Schema.org is a widely adopted vocabulary for semantic annotation of content and data. However, its generic nature makes it complicated for data publishers to pick right types and properties for a specific domain and task. In this paper we propose a formal approach, a domain specification process that generates domain specific patterns by applying operators implemented in SHACL to the schema.org vocabulary. These patterns can support knowledge generation and assessment processes for specific domains and tasks. We demonstrated our approach with use cases in tourism domain.},
	urldate = {2021-10-29},
	journal = {arXiv:1906.06492 [cs]},
	author = {Şimşek, Umutcan and Angele, Kevin and Kärle, Elias and Panasiuk, Oleksandra and Fensel, Dieter},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.06492},
	keywords = {Computer Science - Databases, Computer Science - Information Retrieval},
}

@book{hogan_web_2020,
	address = {Cham},
	title = {The {Web} of {Data}},
	isbn = {978-3-030-51579-9 978-3-030-51580-5},
	url = {https://drive.switch.ch/index.php/f/4052716889},
	language = {en},
	urldate = {2021-10-29},
	publisher = {Springer International Publishing},
	author = {Hogan, Aidan},
	year = {2020},
	doi = {10.1007/978-3-030-51580-5},
}

@book{pan_semantic_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Semantic} {Web} – {ISWC} 2020: 19th {International} {Semantic} {Web} {Conference}, {Athens}, {Greece}, {November} 2–6, 2020, {Proceedings}, {Part} {I}},
	volume = {12506},
	isbn = {978-3-030-62418-7 978-3-030-62419-4},
	shorttitle = {The {Semantic} {Web} – {ISWC} 2020},
	url = {https://drive.switch.ch/index.php/f/4052716884},
	language = {en},
	urldate = {2021-10-29},
	publisher = {Springer International Publishing},
	editor = {Pan, Jeff Z. and Tamma, Valentina and d’Amato, Claudia and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
	year = {2020},
	doi = {10.1007/978-3-030-62419-4},
}

@book{pan_semantic_2020-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Semantic} {Web} – {ISWC} 2020: 19th {International} {Semantic} {Web} {Conference}, {Athens}, {Greece}, {November} 2–6, 2020, {Proceedings}, {Part} {II}},
	volume = {12507},
	isbn = {978-3-030-62465-1 978-3-030-62466-8},
	shorttitle = {The {Semantic} {Web} – {ISWC} 2020},
	url = {https://drive.switch.ch/index.php/f/4052717319},
	language = {en},
	urldate = {2021-10-29},
	publisher = {Springer International Publishing},
	editor = {Pan, Jeff Z. and Tamma, Valentina and d’Amato, Claudia and Janowicz, Krzysztof and Fu, Bo and Polleres, Axel and Seneviratne, Oshani and Kagal, Lalana},
	year = {2020},
	doi = {10.1007/978-3-030-62466-8},
}

@book{fensel_knowledge_2020-1,
	address = {Cham},
	title = {Knowledge {Graphs}: {Methodology}, {Tools} and {Selected} {Use} {Cases}},
	isbn = {978-3-030-37438-9 978-3-030-37439-6},
	shorttitle = {Knowledge {Graphs}},
	url = {https://drive.switch.ch/index.php/f/4052716499},
	language = {en},
	urldate = {2021-10-29},
	publisher = {Springer International Publishing},
	author = {Fensel, Dieter and Şimşek, Umutcan and Angele, Kevin and Huaman, Elwin and Kärle, Elias and Panasiuk, Oleksandra and Toma, Ioan and Umbrich, Jürgen and Wahler, Alexander},
	year = {2020},
	doi = {10.1007/978-3-030-37439-6},
}

@article{noauthor_notitle_nodate-1,
}

@inproceedings{klein_ontology_2001,
	address = {Aachen, DEU},
	series = {{SWWS}'01},
	title = {Ontology {Versioning} on the {Semantic} {Web}},
	url = {https://drive.switch.ch/index.php/f/4068694339},
	abstract = {Ontologies are often seen as basic building blocks for the Semantic Web, as they provide a reusable piece of knowledge about a specific domain. However, those pieces of knowledge are not static, but evolve over time. Domain changes, adaptations to different tasks, or changes in the conceptualization require modifications of the ontology. The evolution of ontologies causes operability problems, which will hamper their effective reuse. A versioning mechanism might help to reduce those problems, as it will make the relations between different revisions of an ontology explicit. This paper will discuss the problem of ontology versioning. Inspired by the work done in database schema versioning and program interface versioning, it will also propose building blocks for the most important aspects of a versioning mechanism, i.e., ontology identification and change specification.},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Semantic} {Web} {Working}},
	publisher = {CEUR-WS.org},
	author = {Klein, Michel and Fensel, Dieter},
	year = {2001},
	note = {event-place: California},
	pages = {75--91},
}

@article{gayo_validating_2017,
	title = {Validating {RDF} {Data}},
	volume = {7},
	issn = {2160-4711, 2160-472X},
	url = {http://book.validatingrdf.com/},
	doi = {10.2200/S00786ED1V01Y201707WBE016},
	language = {en},
	number = {1},
	urldate = {2021-11-01},
	journal = {Synthesis Lectures on the Semantic Web: Theory and Technology},
	author = {Gayo, Jose Emilio Labra and Prud'hommeaux, Eric and Boneva, Iovka and Kontokostas, Dimitris},
	month = sep,
	year = {2017},
	pages = {1--328},
}

@inproceedings{berendt_what_2015,
	address = {Aachen},
	title = {What the {Adoption} of schema.org {Tells} {About} {Linked} {Open} {Data}},
	volume = {1362},
	url = {https://drive.switch.ch/index.php/f/4150807789},
	language = {English},
	booktitle = {Joint {Proceedings} of the 5th {International} {Workshop} on {Using} the {Web} in the {Age} of {Data} ({USEWOD} '15) and the 2nd {International} {Workshop} on {Dataset} {PROFIling} and {fEderated} {Search} for {Linked} {Data} ({PROFILES} '15) ... 12th {European} {Semantic} {Web} {Conference}},
	publisher = {RWTH},
	author = {Paulheim, Heiko},
	editor = {Berendt, Bettina},
	year = {2015},
	note = {Journal Abbreviation: CEUR Workshop Proceedings},
	pages = {85--90},
}

@article{devaraju_automated_2021,
	title = {An automated solution for measuring the progress toward {FAIR} research data},
	volume = {2},
	issn = {26663899},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666389921002324},
	doi = {10.1016/j.patter.2021.100370},
	language = {en},
	number = {11},
	urldate = {2021-11-22},
	journal = {Patterns},
	author = {Devaraju, Anusuriya and Huber, Robert},
	month = nov,
	year = {2021},
	pages = {100370},
}

@article{wu_guidelines_2021,
	title = {Guidelines for publishing structured metadata on the {Web}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://zenodo.org/record/5727048#.YaSw19BBy70},
	doi = {10.15497/RDA00066},
	abstract = {The FAIR principles refer frequently to metadata as a key enabler in discoverability, but also having a major role in accessibility and reusability. Publishing structured metadata on the web can provide a simple and efficient means to increase the FAIRness of research resources: it exposes metadata contained in web pages through a formal mechanism, allowing systematic collection and processing by web-based crawlers. Efforts to adopt structured metadata within and across domains would benefit greatly from a set of recommendations that would help ensure consistent implementation leading to enhanced discoverability and accessibility of data. Based on community consultation and subsequent work, this guidelines provides nine recommendations to support the process of publishing structured metadata on the web, namely: Recommendation 1: Clarify the purpose(s) of your markup Recommendation 2: Identify what resource are to be marked up with structured data Recommendation 3: Adopt or develop a crosswalk from a repository schema to markup vocabulary Recommendation 4: Incorporate external vocabulary if it helps to improve data discoverability and interoperability Recommendation 5: Implement markup syntax consistently by following community practices Recommendation 6: Be friendly to web crawlers Recommendation 7: Make the best use of available tools for mapping, generating and validating structured data Recommendation 8: Document and share every step Recommendation 9: Find and join a community, and follow their established practices},
	language = {en},
	urldate = {2021-12-03},
	author = {Wu, Mingfang and Juty, Nick and {RDA Research Metadata Schemas WG} and Collins, Julia and Duerr, Ruth and Ridsdale, Chantel and Shepherd, Adam and Verhey, Chantelle and Castro, Leyla Jael},
	year = {2021},
	note = {Publisher: Research Data Alliance
Version Number: 3.1},
}

@inproceedings{richardson_user-friendly_2021,
	address = {Virtual Event USA},
	title = {User-friendly {Composition} of {FAIR} {Workflows} in a {Notebook} {Environment}},
	isbn = {978-1-4503-8457-5},
	url = {https://dl.acm.org/doi/10.1145/3460210.3493546},
	doi = {10.1145/3460210.3493546},
	language = {en},
	urldate = {2021-12-06},
	booktitle = {Proceedings of the 11th on {Knowledge} {Capture} {Conference}},
	publisher = {ACM},
	author = {Richardson, Robin A. and Celebi, Remzi and van der Burg, Sven and Smits, Djura and Ridder, Lars and Dumontier, Michel and Kuhn, Tobias},
	month = dec,
	year = {2021},
	pages = {1--8},
}
